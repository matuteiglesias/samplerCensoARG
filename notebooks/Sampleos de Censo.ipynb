{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esta Notebook construye muestreos del Censo 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para correrla necesita tener los archivos de la base de Datos del Censo 2010.  \n",
    "\n",
    "   - La base de Datos en formato REDATAM disponible en el repositorio no oficial de datos abierto (DatAR)\n",
    "\n",
    "http://datar.info/dataset/censo-nacional-de-poblacion-hogares-y-viviendas-2010-cd-redatam\n",
    "\n",
    "   - Un convertidor de REDATAM (funciona en Windows) disponible en:\n",
    "    \n",
    "https://www.aacademica.org/conversor.redatam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## El path donde tenemos los archivos PERSONA, HOGAR y VIVIENDA\n",
    "censo_DB_path = '/media/miglesia/Elements/suite/ext_CPV2010_basico_radio_pub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poblacion por departamento (Comuna, Partido) en 2001 - 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DPTO</th>\n",
       "      <th>NOMDPTO</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>...</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>2024</th>\n",
       "      <th>2025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>Comuna 01</td>\n",
       "      <td>223620</td>\n",
       "      <td>225878</td>\n",
       "      <td>228137</td>\n",
       "      <td>230395</td>\n",
       "      <td>232654</td>\n",
       "      <td>234912</td>\n",
       "      <td>237171</td>\n",
       "      <td>239429</td>\n",
       "      <td>...</td>\n",
       "      <td>252053</td>\n",
       "      <td>253271</td>\n",
       "      <td>254408</td>\n",
       "      <td>255457</td>\n",
       "      <td>256405</td>\n",
       "      <td>257235</td>\n",
       "      <td>257934</td>\n",
       "      <td>258497</td>\n",
       "      <td>258922</td>\n",
       "      <td>259205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>Comuna 02</td>\n",
       "      <td>138156</td>\n",
       "      <td>139551</td>\n",
       "      <td>140947</td>\n",
       "      <td>142342</td>\n",
       "      <td>143737</td>\n",
       "      <td>145133</td>\n",
       "      <td>146528</td>\n",
       "      <td>147923</td>\n",
       "      <td>...</td>\n",
       "      <td>149848</td>\n",
       "      <td>149720</td>\n",
       "      <td>149607</td>\n",
       "      <td>149510</td>\n",
       "      <td>149430</td>\n",
       "      <td>149371</td>\n",
       "      <td>149337</td>\n",
       "      <td>149328</td>\n",
       "      <td>149345</td>\n",
       "      <td>149389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DPTO    NOMDPTO    2001    2002    2003    2004    2005    2006    2007  \\\n",
       "0  2001  Comuna 01  223620  225878  228137  230395  232654  234912  237171   \n",
       "1  2002  Comuna 02  138156  139551  140947  142342  143737  145133  146528   \n",
       "\n",
       "     2008  ...    2016    2017    2018    2019    2020    2021    2022  \\\n",
       "0  239429  ...  252053  253271  254408  255457  256405  257235  257934   \n",
       "1  147923  ...  149848  149720  149607  149510  149430  149371  149337   \n",
       "\n",
       "     2023    2024    2025  \n",
       "0  258497  258922  259205  \n",
       "1  149328  149345  149389  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# El archivo 'proy_pop200125.csv' contiene la informacion oficial de proyecciones de poblacion por departamento publicada por INDEC\n",
    "#  ('https://www.indec.gob.ar/ftp/cuadros/poblacion/proyeccion_departamentos_10_25.pdf')\n",
    "proy_pop = pd.read_csv('./../data/info/proy_pop200125.csv', encoding = 'utf-8')\n",
    "proy_pop.head(2)\n",
    "# proy_pop.sample(5).iloc[:, 2:].T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencia de radios censales 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Referencia de radios censales segun Censo 2010\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv')\n",
    "radio_ref['DPTO'] = radio_ref['DPTO'].astype(int)\n",
    "radio_ref['PROV'] = radio_ref['PROV'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "radio_ref[['DPTO', 'NOMDPTO']].drop_duplicates().to_csv('./../data/info/dptos.csv', index = False)\n",
    "radio_ref[['PROV', 'NOMPROV']].drop_duplicates().to_csv('./../data/info/provs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personas por hogar (columna IX_TOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOGAR_REF_ID</th>\n",
       "      <th>IX_TOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>746811</td>\n",
       "      <td>1694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5317447</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10234703</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1602541</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8717569</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HOGAR_REF_ID  IX_TOT\n",
       "0        746811    1694\n",
       "1       5317447    1628\n",
       "2      10234703    1520\n",
       "3       1602541    1410\n",
       "4       8717569    1373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not os.path.exists('./../data/info/IX_TOT.csv'):\n",
    "#     # Cantidad de personas  en cada hogar. No esta la columna pero la podemos construir..\n",
    "#     PERSONA = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/PERSONA.csv', sep = ';', usecols = ['HOGAR_REF_ID']) \n",
    "#     # Los datasets csv del censo fueron extraidos en ext_CPV2010_basico_radio_pub\n",
    "#     # Pesa algunos Gb, por eso se carga con dask.\n",
    "\n",
    "#     with ProgressBar():\n",
    "#         IX_TOT = PERSONA['HOGAR_REF_ID'].value_counts().reset_index().compute()\n",
    "#         IX_TOT.columns = ['HOGAR_REF_ID', 'IX_TOT']\n",
    "\n",
    "#     IX_TOT.to_csv('./../data/info/IX_TOT.csv', index = False)\n",
    "\n",
    "# else:\n",
    "#     IX_TOT = pd.read_csv('./../data/info/IX_TOT.csv')\n",
    "\n",
    "# IX_TOT.head() # el tamanio de 12.197.647 hogares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radio_ref = pd.read_csv('./../Censo_individual/data/radio_ref.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hogar y Vivienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 38.6s\n"
     ]
    }
   ],
   "source": [
    "# frac = 0.01\n",
    "\n",
    "# #Esto es para extraer las viviendas, hogares y personas de los partidos (DPTOs) en cuestion.\n",
    "# # seleccion_DPTOS y usecols nos sirven para no cargar data innecesaria.\n",
    "# VIVIENDA = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/VIVIENDA.csv', sep = ';', usecols = ['VIVIENDA_REF_ID', 'RADIO_REF_ID', 'TIPVV', 'V01'])\n",
    "# VIVIENDA = VIVIENDA.merge(radio_ref[['RADIO_REF_ID', 'DPTO']])\n",
    "# # VIVIENDA_ = VIVIENDA.loc[VIVIENDA.DPTO.isin(seleccion_DPTOS)]\n",
    "    \n",
    "# HOGAR = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID']) # csv is too big, so it is dask-loaded. Not sure it's efficient thou\n",
    "\n",
    "# with ProgressBar():\n",
    "#     HOGAR_DPTO = HOGAR.merge(VIVIENDA[['VIVIENDA_REF_ID', 'DPTO']]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seleccion_distritos = ['02', '04']\n",
    "\n",
    "if len(np.unique([len(dist) for dist in seleccion_distritos])) != 1:\n",
    "    print('Imputar solo provincias o bien solo departamentos.')\n",
    "    \n",
    "nivel = np.unique([len(dist) for dist in seleccion_distritos])[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.01\n",
    "\n",
    "#Esto es para extraer las viviendas, hogares y personas de los partidos (DPTOs) en cuestion.\n",
    "# seleccion_DPTOS y usecols nos sirven para no cargar data innecesaria.\n",
    "VIVIENDA = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/VIVIENDA.csv', sep = ';', usecols = ['VIVIENDA_REF_ID', 'RADIO_REF_ID', 'TIPVV', 'V01'])\n",
    "VIVIENDA = VIVIENDA.merge(radio_ref[['RADIO_REF_ID', 'DPTO', 'PROV']])\n",
    "\n",
    "if nivel == 2:\n",
    "    VIVIENDA = VIVIENDA.loc[VIVIENDA.PROV.isin(seleccion_distritos)]\n",
    "    \n",
    "elif nivel == 4:\n",
    "    VIVIENDA = VIVIENDA.loc[VIVIENDA.DPTO.isin(seleccion_distritos)]\n",
    "    \n",
    "HOGAR = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID']) # csv is too big, so it is dask-loaded. Not sure it's efficient thou\n",
    "\n",
    "with ProgressBar():\n",
    "    HOGAR_DPTO = HOGAR.merge(VIVIENDA[['VIVIENDA_REF_ID', 'DPTO']]).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # poblacion 2010 por depto\n",
    "# # Personas\n",
    "# P02 = pd.read_csv('./../data/info/PERSONA-P02.csv', encoding = 'latin-1')\n",
    "\n",
    "# P02['DPTO'] = P02['radio'].astype(str).str.zfill(9).str[:5].astype(int)\n",
    "# PERSONAS = P02.groupby('DPTO')[['TOTAL']].sum()\n",
    "\n",
    "# # Hogares\n",
    "# HOGARES = HOGAR_DPTO.groupby(['DPTO']).nunique()\n",
    "\n",
    "# poblacion = HOGARES.join(PERSONAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'ARG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4e9dedac6470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHOGAR_DPTO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratios\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DPTO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DPTO'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     HOGAR = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'H05', 'H06', 'H07', 'H08',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mresult_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrameOrSeries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# calling splitter.fast_apply will raise TypeError via apply_frame_axis0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_get_sorted_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3350\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3351\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m   1448\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 blk.take_nd(\n\u001b[1;32m   1286\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             new_blocks = [\n\u001b[0;32m-> 1285\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m   1286\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     )\n\u001b[0;32m-> 1713\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# grouped = HOGAR_DPTO.merge(proyeccion[['DPTO', 'ratio_18']]).groupby('DPTO')\n",
    "# ratios = proy_pob.div(proy_pob['2010'], 0).reset_index()\n",
    "ratios = proy_pop.set_index(['DPTO', 'NOMDPTO']).div(proy_pop['2010'].values, 0).reset_index()\n",
    "\n",
    "PERSONA = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/PERSONA.csv', sep = ';', usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID', 'P01', 'P02', 'P03', 'P05', 'P06',\n",
    "       'P07', 'P12', 'P08', 'P09', 'P10', 'CONDACT'])\n",
    "    \n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    grouped = HOGAR_DPTO.merge(ratios[['DPTO', yr]]).groupby('DPTO')\n",
    "    sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean()))\n",
    "\n",
    "    HOGAR = dd.read_csv(censo_DB_path + 'ext_CPV2010_basico_radio_pub/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'H05', 'H06', 'H07', 'H08',\n",
    "           'H09', 'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP', 'TOTPERS']) \n",
    "\n",
    "    VIVIENDA_sample = VIVIENDA.loc[VIVIENDA.VIVIENDA_REF_ID.isin(sample.VIVIENDA_REF_ID)]\n",
    "    HOGAR_sample = HOGAR.loc[HOGAR.HOGAR_REF_ID.isin(sample.HOGAR_REF_ID)]\n",
    "\n",
    "    tabla_censo = VIVIENDA_sample.merge(HOGAR_sample)\n",
    "#     tabla_censo = tabla_censo.merge(IX_TOT) # se mergea mas adelante\n",
    "\n",
    "    with ProgressBar():\n",
    "        table = tabla_censo.compute()\n",
    "\n",
    "    # Adaptamos las categorias de respuestas para que queden iguales a las de la EPH\n",
    "    table['V01'] = table['V01'].map({1:1, 2:6, 3:6, 4:2, 5:3, 6:4, 7:5, 8:6})\n",
    "    table['H06'] = table['H06'].map({1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:9})\n",
    "    table['H09'] = table['H09'].map({1:1, 2:2, 3:3, 4:4, 5:4, 6:4})\n",
    "    table['H16'] = table['H16'].clip(0, 9)\n",
    "    table['H14'] = table['H14'].map({1:1, 2:4, 3:2, 4:2, 5:4, 6:3, 7:4, 8:9})\n",
    "    table['H13'] = table['H13'].map({1:1, 2:2, 4:0})\n",
    "\n",
    "    # saber de que aglo es el hogar.\n",
    "    table = table.merge(radio_ref[['RADIO_REF_ID','AGLOMERADO']]) \n",
    "\n",
    "# #    Option to save table now, in case it crashes at this step.\n",
    "#     if not os.path.exists('./../data/yr_samples/'):\n",
    "#         os.makedirs('./../data/yr_samples/')\n",
    "#     table.to_csv('./../data/yr_samples/sample_censo_table_f'+str(frac)+'_'+yr+'_ARG.csv', index = False)\n",
    "\n",
    "    PERSONA_sample = PERSONA.loc[PERSONA.HOGAR_REF_ID.isin(sample.HOGAR_REF_ID)]\n",
    "\n",
    "\n",
    "    with ProgressBar():\n",
    "        table = table.merge(PERSONA_sample.compute())\n",
    "\n",
    "    # Adaptamos las categorias de respuestas para que iguales las de la EPH\n",
    "    table['P07'] = table['P07'].map({1:1, 2:2, 0:2})\n",
    "    \n",
    "    ## Calcula tamano del hogar\n",
    "    IX_TOT = table['HOGAR_REF_ID'].value_counts().reset_index(); IX_TOT.columns = ['HOGAR_REF_ID', 'IX_TOT_']\n",
    "    table = table.merge(IX_TOT)\n",
    "\n",
    "    # Guardar sampleo del censo\n",
    "    \n",
    "    if not os.path.exists('./../data/censo_samples/'):\n",
    "        os.makedirs('./../data/censo_samples/')\n",
    "        \n",
    "    table.to_csv('./../data/censo_samples/table_f'+str(frac)+'_'+yr+'_'+name+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_ = pd.read_csv('./../../yr_samples/sample_censo_table_f0.02_2020_ARG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
