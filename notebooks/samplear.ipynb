{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parseo de Argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse # Importing the argparse module to handle command line arguments\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-dbp', '--databasepath', required=True, help='Path to the database')\n",
    "parser.add_argument('-f','--frac', type=float, default = 0.01, help='Fraction of the sample')\n",
    "parser.add_argument('-n','--nombre', default= 'ARG', help='Name of the sample')\n",
    "parser.add_argument('-y','--years', nargs=2, type=int, default=[2021, 2022], help='Years to sample')\n",
    "\n",
    "distritos = parser.add_mutually_exclusive_group()\n",
    "distritos.add_argument('-d','--departamentos', nargs='+', type = int, help='Departments to sample')\n",
    "distritos.add_argument('-p','--provincias', nargs='+', type = int, help='Provinces to sample')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "censo_DB_path = args.databasepath\n",
    "frac = args.frac\n",
    "name = args.nombre\n",
    "startyr, endyr = args.years\n",
    "\n",
    "if args.departamentos is None and args.provincias is None:\n",
    "    total_pais = True\n",
    "\n",
    "# To show the results of the given option to screen.\n",
    "for _, value in parser.parse_args()._get_kwargs():\n",
    "    if value is not None:\n",
    "        print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# censo_DB_path = '/media/matias/Elements/suite/ext_CPV2010_basico_radio_pub'\n",
    "# frac = 0.002\n",
    "# name = 'ARG_test'\n",
    "# startyr, endyr = 2015, 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Importing the numpy module for numerical computations\n",
    "import pandas as pd # Importing the pandas module for data manipulation and analysis\n",
    "import os # Importing the os module for interacting with the operating system\n",
    "import dask.dataframe as dd # Importing the dask.dataframe module for parallel computing on large datasets\n",
    "from dask.diagnostics import ProgressBar # Importing the ProgressBar class from dask.diagnostics to display progress of computations using dask.dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El archivo 'proy_pop200125.csv' contiene la informacion oficial de proyecciones de poblacion por departamento publicada por INDEC\n",
    "#  ('https://www.indec.gob.ar/ftp/cuadros/poblacion/proyeccion_departamentos_10_25.pdf')\n",
    "proy_pop = pd.read_csv('./../data/info/proy_pop200125.csv', encoding = 'utf-8')\n",
    "\n",
    "# Proyeccion de poblacion por departamento\n",
    "ratios = proy_pop.set_index(['DPTO', 'NOMDPTO']).div(proy_pop['2010'].values, 0).reset_index()\n",
    "\n",
    "## Referencia de radios censales segun Censo 2010\n",
    "radio_ref = pd.read_csv('./../data/info/radio_ref.csv').astype({'DPTO':int, 'PROV':int})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIVIENDA = dd.read_csv(censo_DB_path + '/VIVIENDA.csv', sep = ';',\n",
    "                       usecols = ['VIVIENDA_REF_ID', 'RADIO_REF_ID', 'URP', 'TIPVV', 'V01'])\n",
    "\n",
    "HOGAR = dd.read_csv(censo_DB_path + '/HOGAR.csv', sep = ';', usecols = ['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'H05', 'H06', 'H07', 'H08',\n",
    "        'H09', 'H10', 'H11', 'H12', 'H13', 'H14', 'H15', 'H16', 'PROP', 'TOTPERS']) \n",
    "\n",
    "PERSONA = dd.read_csv(censo_DB_path + '/PERSONA.csv', sep = ';', usecols = ['PERSONA_REF_ID', 'HOGAR_REF_ID', \n",
    "'P01', 'P02', 'P03', 'P05', 'P06', 'P07', 'P12', 'P08', 'P09', 'P10', 'CONDACT'])\n",
    "\n",
    "\n",
    "HOGAR = HOGAR.merge(VIVIENDA[['VIVIENDA_REF_ID', 'RADIO_REF_ID']], on='VIVIENDA_REF_ID')\n",
    "\n",
    "PERSONA = PERSONA.merge(HOGAR[['HOGAR_REF_ID', 'RADIO_REF_ID']], on = 'HOGAR_REF_ID')\n",
    "\n",
    "geo_vars = ['RADIO_REF_ID', 'DPTO', 'PROV', 'AGLOMERADO']\n",
    "info = radio_ref[geo_vars]\n",
    "\n",
    "VIVIENDA = VIVIENDA.merge(info, on = 'RADIO_REF_ID')\n",
    "\n",
    "HOGAR = HOGAR.merge(info, on = 'RADIO_REF_ID')\n",
    "\n",
    "PERSONA = PERSONA.merge(info, on = 'RADIO_REF_ID')\n",
    "\n",
    "## Filtrar por departamento o provincia\n",
    "def filter_dataframe(df, args):\n",
    "    if args.departamentos is not None:\n",
    "        df = df[df.DPTO.isin(args.departamentos)]\n",
    "    elif args.provincias is not None:\n",
    "        df = df[df.PROV.isin(args.provincias)]\n",
    "    else:\n",
    "        print('total_pais')\n",
    "    return df\n",
    "\n",
    "VIVIENDA = filter_dataframe(VIVIENDA, args)\n",
    "HOGAR = filter_dataframe(HOGAR, args)\n",
    "PERSONA = filter_dataframe(PERSONA, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar sampleo del censo\n",
    "if not os.path.exists('./../data/censo_samples/'):\n",
    "    os.makedirs('./../data/censo_samples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3778/675829219.py:9: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean())).compute()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3778/675829219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# compute the final dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import delayed, compute\n",
    "\n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    \n",
    "    grouped = HOGAR[['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'DPTO']].merge(ratios[['DPTO', yr]]).groupby('DPTO')\n",
    "    # sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean()), meta=('x', 'f8')).compute()\n",
    "    sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean())).compute()\n",
    "\n",
    "    viviendas_en_sample = sample.VIVIENDA_REF_ID.unique()\n",
    "    hogares_en_sample = sample.HOGAR_REF_ID.unique()\n",
    "\n",
    "    # Use persist to keep the intermediate dataframe in memory\n",
    "    VIVIENDA_sample = VIVIENDA.loc[VIVIENDA.VIVIENDA_REF_ID.isin(viviendas_en_sample)].persist()\n",
    "    HOGAR_sample = HOGAR.loc[HOGAR.HOGAR_REF_ID.isin(hogares_en_sample)].persist()\n",
    "    PERSONA_sample = PERSONA.loc[PERSONA.HOGAR_REF_ID.isin(hogares_en_sample)].persist()\n",
    "\n",
    "    # Use delayed function to schedule computation\n",
    "    merge1 = delayed(VIVIENDA_sample.merge)(HOGAR_sample, on = ['VIVIENDA_REF_ID'] + geo_vars)\n",
    "    merge2 = delayed(merge1.merge)(PERSONA_sample, on = ['HOGAR_REF_ID'] + geo_vars)\n",
    "\n",
    "    # persist the dataframe in memory\n",
    "    merge2 = merge2.persist()\n",
    "\n",
    "    # compute the final dataframe\n",
    "    with ProgressBar():\n",
    "        df = merge2.compute(num_workers=4)\n",
    "\n",
    "    # Save the sample data\n",
    "    filename = f'./../data/censo_samples/table_f{frac}_{yr}_{name}.csv'\n",
    "    df.to_csv(filename, index = False, single_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15043/208850193.py:4: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean())).compute()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 58.8s\n",
      "25727\n",
      "[########################################] | 100% Completed |  2min 48.8s\n",
      "84605\n",
      "[########################################] | 100% Completed |  3min  8.6s\n",
      "saved file: ./../data/censo_samples/table_f0.002_2015_ARG.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "#     print(yr)\n",
    "#     grouped = HOGAR[['HOGAR_REF_ID', 'VIVIENDA_REF_ID', 'DPTO']].merge(ratios[['DPTO', yr]]).groupby('DPTO')\n",
    "#     sample = grouped.apply(lambda x: x.sample(frac=frac*x[yr].mean())).compute()\n",
    "\n",
    "#     viviendas_en_sample = sample.VIVIENDA_REF_ID.unique()\n",
    "#     hogares_en_sample = sample.HOGAR_REF_ID.unique()\n",
    "\n",
    "#     with ProgressBar():\n",
    "#         VIVIENDA_sample = VIVIENDA.loc[VIVIENDA.VIVIENDA_REF_ID.isin(viviendas_en_sample)]\n",
    "#         HOGAR_sample = HOGAR.loc[HOGAR.HOGAR_REF_ID.isin(hogares_en_sample)]\n",
    "#         PERSONA_sample = PERSONA.loc[PERSONA.HOGAR_REF_ID.isin(hogares_en_sample)]\n",
    "\n",
    "#         merge1 = VIVIENDA_sample.merge(HOGAR_sample, on = ['VIVIENDA_REF_ID'] + geo_vars)\n",
    "#         print(len(merge1))\n",
    "#         merge2 = merge1.merge(PERSONA_sample, on = ['HOGAR_REF_ID'] + geo_vars)\n",
    "#         print(len(merge2))\n",
    "    \n",
    "#         df = merge2.compute()\n",
    "\n",
    "#     # Guardar sampleo del censo\n",
    "#     if not os.path.exists('./../data/censo_samples/'):\n",
    "#         os.makedirs('./../data/censo_samples/')\n",
    "        \n",
    "#     filename = './../data/censo_samples/table_f'+str(frac)+'_'+yr+'_'+name+'.csv'\n",
    "#     print('saved file: ' + filename)\n",
    "#     df.to_csv(filename, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cef6941c3b284b72330916f92da3863815d2ff6730070ac04dc0833f8840e48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
